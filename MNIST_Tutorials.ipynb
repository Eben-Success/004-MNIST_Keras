{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwNyacMW5xh76pEFKCNrUK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eben-Success/004-MNIST_Keras/blob/main/MNIST_Tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX-UmVu1Qdap",
        "outputId": "bae94bdc-93ca-439e-fa9e-27c593b3aa7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the Fashio MNIST dataset\n",
        "fmist = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "ijoIbdxZQuhr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training and test split of the Fashion MNISt datasets\n",
        "(training_images, training_labels), (test_images, test_labels) = fmist.load_data()"
      ],
      "metadata": {
        "id": "g7bKLSycRZvh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# You can put between 0 to 59999 here\n",
        "index = 456\n",
        "\n",
        "# Set number of characters per row when printing\n",
        "np.set_printoptions(linewidth=320)\n",
        "\n",
        "# Print the label and image\n",
        "print(f\"LABEL: {training_labels[index]}\")\n",
        "print(f\"  \\nIMAGE PIXEL ARRAY: \\n {training_images[index]}\")\n",
        "\n",
        "# Visualize the image\n",
        "plt.imshow(training_images[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "tzADRKaDRpLV",
        "outputId": "f27b7776-ce35-4ebc-931c-e4a4c42237c6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL: 1\n",
            "  \n",
            "IMAGE PIXEL ARRAY: \n",
            " [[  0   0   0   0   0   0   0   0   0  58 145 106 111  52  83 127 106 101 146  23   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  97 161 175 178 182 230 254 159 127 143  80   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 106 172 154 128 163 254 170 156 182 135  68   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 120 109 111 117 139 104 123 113 119 160 115   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 130 134 143 156 165 126 164 128  98 116 119   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 128 124 122 143 190 234 168 130 120 132 120   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 137 111 124 142 250 246 156 142 124 128 130   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 128 146 123 174 191 123 167 128 127 143 100   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 109 138 106 201 108  80 157 120 104 139  61   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  98 150 115 179  97  91 198 102 120 139  21   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  71 164 115 176  91  60 219 108 123 139   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  43 180 119 183  86   2 215 117 137 112   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   6 185 112 185  74   0 222 115 146  79   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 180 131 198  72   0 220 112 154  47   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 170 135 194  54   0 208  98 152  26   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 146 137 208  69   0 209 109 157  20   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 145 146 233  78   0 223 122 154  13   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 168 175 223  24   0 220 150 150   1   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 183 180 201   4   0 200 161 156   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 202 180 205   6   0 215 167 179   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 200 174 209  31   0 230 164 160   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 198 179 220  21   0 234 175 159   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 186 185 213   0   0 230 182 171   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 160 183 201   0   0 219 186 131   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 152 180 186   0   0 207 183 102   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 154 182 168   0   0 175 180  93   0   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 154 193 185   0   0 178 174  82   0   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  94 193 128   0   0 189 163  31   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f264862d910>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the pixel values of the train and test images\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "wIoP3qUVSVu_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the classification model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "metadata": {
        "id": "BeCWFz_KS1FU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential: That defines a sequence of layers in the neural network.\n",
        "\n",
        "Flatten: Remember earlier where our images were a 28x28 pixel matrix when you printed them out? Flatten just takes that square and turns it into a 1-dimensional array.\n",
        "\n",
        "Dense: Adds a layer of neurons\n",
        "\n",
        "Each layer of neurons need an activation function to tell them what to do. There are a lot of options, but just use these for now:\n",
        "\n",
        "ReLU effectively means:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "if x > 0:\n",
        "  return x\n",
        "\n",
        "else:\n",
        "  return 0\n",
        "```\n",
        "\n",
        "In other words, it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "Softmax takes a list of values and scales these so the sum of all elements will be equal to 1. When applied to model outputs, you can think of the scaled values as the probability for that class. For example, in your classification model which has 10 units in the output dense layer, having the highest value at index = 4 means that the model is most confident that the input clothing image is a coat. "
      ],
      "metadata": {
        "id": "Wp8FqbIEWOwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare sample inputs and converts to a tensor\n",
        "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
        "inputs = tf.convert_to_tensor(inputs)\n",
        "print(f\"input to softmax function: {inputs.numpy()}\")\n",
        "\n",
        "# Feed the inputs to a softmax activation functiono\n",
        "outputs = tf.keras.activations.softmax(inputs)\n",
        "print(f\"ouput of softmax function: {outputs.numpy()}\")\n",
        "\n",
        "# Get the sum of all values after the softmax\n",
        "sum = tf.reduce_sum(outputs)\n",
        "print(f\"sum of ouputs: {sum}\")\n",
        "\n",
        "# Get index with highest value\n",
        "prediction = np.argmax(outputs)\n",
        "print(f\"class with highest probability: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkmOa7HbTJKO",
        "outputId": "4af58a36-ee3c-45a9-8369-aadfe393e9cf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input to softmax function: [[1. 3. 4. 2.]]\n",
            "ouput of softmax function: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
            "sum of ouputs: 1.0\n",
            "class with highest probability: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(), \n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1I6Mr55XaY0",
        "outputId": "bccdfa53-25e4-4dd8-d91a-78e31d29def5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4758 - accuracy: 0.8303\n",
            "Epoch 2/5\n",
            "1125/1875 [=================>............] - ETA: 3s - loss: 0.3684 - accuracy: 0.8657"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on unseen data\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "ihPGZrZaYbt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification = model.predict(test_images)\n",
        "print(classification[0])"
      ],
      "metadata": {
        "id": "Z_-PFjIEYwO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "UOCCRyfiZIgD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}